{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2282a5e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8316/2174554168.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\project\\model\\model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mDefination\u001b[0m \u001b[0mof\u001b[0m \u001b[0mNN\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecurrent\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGRU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train the NN model.\n",
    "\"\"\"\n",
    "import sys\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from data.data import process_data\n",
    "from model import model\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, name, config):\n",
    "    \"\"\"train\n",
    "    train a single model.\n",
    "\n",
    "    # Arguments\n",
    "        model: Model, NN model to train.\n",
    "        X_train: ndarray(number, lags), Input data for train.\n",
    "        y_train: ndarray(number, ), result data for train.\n",
    "        name: String, name of model.\n",
    "        config: Dict, parameter for train.\n",
    "    \"\"\"\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mape'])\n",
    "    # early = EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "    hist = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=config[\"batch\"],\n",
    "        epochs=config[\"epochs\"],\n",
    "        validation_split=0.05)\n",
    "\n",
    "    model.save('model/' + name + '.h5')\n",
    "    df = pd.DataFrame.from_dict(hist.history)\n",
    "    df.to_csv('model/' + name + ' loss.csv', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "def train_seas(models, X_train, y_train, name, config):\n",
    "    \"\"\"train\n",
    "    train the SAEs model.\n",
    "\n",
    "    # Arguments\n",
    "        models: List, list of SAE model.\n",
    "        X_train: ndarray(number, lags), Input data for train.\n",
    "        y_train: ndarray(number, ), result data for train.\n",
    "        name: String, name of model.\n",
    "        config: Dict, parameter for train.\n",
    "    \"\"\"\n",
    "\n",
    "    temp = X_train\n",
    "    # early = EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "\n",
    "    for i in range(len(models) - 1):\n",
    "        if i > 0:\n",
    "            p = models[i - 1]\n",
    "            hidden_layer_model = Model(input=p.input,\n",
    "                                       output=p.get_layer('hidden').output)\n",
    "            temp = hidden_layer_model.predict(temp)\n",
    "\n",
    "        m = models[i]\n",
    "        m.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mape'])\n",
    "\n",
    "        m.fit(temp, y_train, batch_size=config[\"batch\"],\n",
    "              epochs=config[\"epochs\"],\n",
    "              validation_split=0.05)\n",
    "\n",
    "        models[i] = m\n",
    "\n",
    "    saes = models[-1]\n",
    "    for i in range(len(models) - 1):\n",
    "        weights = models[i].get_layer('hidden').get_weights()\n",
    "        saes.get_layer('hidden%d' % (i + 1)).set_weights(weights)\n",
    "\n",
    "    train_model(saes, X_train, y_train, name, config)\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--model\",\n",
    "        default=\"lstm\",\n",
    "        help=\"Model to train.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    lag = 12\n",
    "    config = {\"batch\": 256, \"epochs\": 600}\n",
    "    file1 = 'data/train.csv'\n",
    "    file2 = 'data/test.csv'\n",
    "    X_train, y_train, _, _, _ = process_data(file1, file2, lag)\n",
    "\n",
    "    if args.model == 'lstm':\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        m = model.get_lstm([12, 64, 64, 1])\n",
    "        train_model(m, X_train, y_train, args.model, config)\n",
    "    if args.model == 'gru':\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "        m = model.get_gru([12, 64, 64, 1])\n",
    "        train_model(m, X_train, y_train, args.model, config)\n",
    "    if args.model == 'saes':\n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]))\n",
    "        m = model.get_saes([12, 400, 400, 400, 1])\n",
    "        train_seas(m, X_train, y_train, args.model, config)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be097b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
